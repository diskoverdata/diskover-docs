name: Deploy to S3

on:
  workflow_dispatch:
    inputs:
      config:
        description: 'Config file path'
        required: true

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [ 3.8 ]

    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}
          architecture: x64

      - name: Install requirements
        run: |
          python3 -m pip install -r requirements.txt
          sudo snap install yq

      - name: Build website
        run: |
          mkdir ./build
          mkdir ./build/docs
          
          cp ./mkdocs.yml ./build/mkdocs.yml
          
          site_name=$(yq e '.website_name' ${{ github.event.inputs.config }}) yq e '.site_name = env(site_name)' -i ./build/mkdocs.yml
          
          i=0
          
          echo "Copying index"
          cp ./shared/$(yq e ".index_document" ${{ github.event.inputs.config }}) ./build/docs/index.md
          
          yq e '.ordered_documents[]' ${{ github.event.inputs.config }} | while read line; do
            echo "Copying $line";
            cp ./shared/$line ./build/docs/$i-$line;
            i=$((i+1))
          done
          
          echo "Copying images"
          cp -r ./shared/images ./build/docs/images
                    
          cd ./build
          python3 -m mkdocs build

#       - name: S3 Sync
#         uses: awact/s3-action@0.1.1
#         with:
#           args: --acl public-read --follow-symlinks --delete
#         env:
#           AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
#           AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
#           AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
#           AWS_REGION: 'us-east-1'
#           SOURCE_DIR: 'build/site'
#           DEST_DIR: ${{ github.event.inputs.folder }}

      - name: S3 sync
        run: |
          aws s3 sync --delete --acl public-read --follow-symlinks ./build/site s3://$AWS_S3_BUCKET/$(yq e '.website_folder' ${{ github.event.inputs.config }}) 
#          aws s3 ls docs.diskoverdata.com
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
          AWS_REGION: 'us-east-1'
        
